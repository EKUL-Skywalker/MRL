{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3cf273",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fbeb4d",
   "metadata": {},
   "source": [
    "## Configuration Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d076c228",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = 'mrl' # one of ['mrl', 'mrl_e', 'ff']\n",
    "NESTING = CONFIG in ['mrl', 'mrl_e']\n",
    "ROOT_DIR = \"path_to_db_and_query_files/\" + CONFIG + \"/\"\n",
    "DATASET = 'imagenet1k'\n",
    "SEARCH_INDEX = 'exactl2' # one of ['exactl2', 'hnsw_8', 'hnsw_32']\n",
    "EVAL_CONFIG = 'vanilla' # ['vanilla', 'reranking', 'funnel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b093168",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "nesting_list is used in two ways depending on the config:\n",
    "1. vanilla: nesting_list = scales at which we retrieve representations for all images\n",
    "2. reranking: nesting_list = scales at which we rerank representations for all images\n",
    "3. funnel: unused\n",
    "'''\n",
    "if EVAL_CONFIG in ['vanilla', 'reranking']:\n",
    "    nesting_list = [8, 16, 32, 64, 128, 256, 512, 1024, 2048]\n",
    "else:\n",
    "    # funnel retrieval\n",
    "    CASCADE_NN_FILE = '8dim-cascade[16, 32, 64, 128, 2048]_[800, 400, 200, 50, 10]shortlist_imagenet4m_exactl2.csv'\n",
    "    nesting_list = [2048] # for funnel, we evaluate a single config at a time\n",
    "\n",
    "'''\n",
    "ret_dim is used in two ways depending on the config:\n",
    "1. vanilla: unused\n",
    "2. reranking: retrieve representations of size ret_dim and rerank with nesting_list\n",
    "3. funnel: unused\n",
    "'''\n",
    "ret_dim = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9351db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mAP_recall_at_k(val_classes, db_classes, neighbors, k):\n",
    "    \"\"\"\n",
    "    Computes the MAP@k (default value of k=R) on neighbors with val set by seeing if nearest neighbor\n",
    "    is in the same class as the class of the val code. Let m be size of val set, and n in train.\n",
    "\n",
    "      val:          (m x d) All the truncated vector representations of images in val set\n",
    "      val_classes:  (m x 1) class index values for each vector in the val set\n",
    "      db_classes:   (n x 1) class index values for each vector in the train set\n",
    "      neighbors:    (k x m) indices in train set of top k neighbors for each vector in val set\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    ImageNet-1K:\n",
    "    shape of val is: (50000, dim)\n",
    "    shape of val_classes is: (50000, 1)\n",
    "    shape of db_classes is: (1281167, 1)\n",
    "    shape of neighbors is: (50000, 100))\n",
    "    \"\"\"\n",
    "\n",
    "    APs = list()\n",
    "    precision, recall, topk = [], [], []\n",
    "    for i in range(val_classes.shape[0]): # Compute precision for each vector's list of k-nn\n",
    "        target = val_classes[i]\n",
    "        indices = neighbors[i, :][:k]    # k neighbor list for ith val vector\n",
    "        labels = db_classes[indices]\n",
    "        matches = (labels == target)\n",
    "    \n",
    "        # topk\n",
    "        hits = np.sum(matches)\n",
    "        if hits>0:\n",
    "            topk.append(1)\n",
    "        else:\n",
    "            topk.append(0)\n",
    "            \n",
    "        # true positive counts\n",
    "        tps = np.cumsum(matches)\n",
    "\n",
    "        # recall\n",
    "        recall.append(np.sum(matches)/1300)\n",
    "        precision.append(np.sum(matches)/k)\n",
    "\n",
    "        # precision values\n",
    "        precs = tps.astype(float) / np.arange(1, k + 1, 1)\n",
    "        APs.append(np.sum(precs[matches.squeeze()]) / k)\n",
    "\n",
    "    return np.mean(APs), np.mean(precision), np.mean(recall), np.mean(topk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74005467",
   "metadata": {},
   "source": [
    "## Load database, query, and neighbor arrays and compute metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1245f078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load database and query set for nested models\n",
    "if NESTING:\n",
    "    # Database: 1.2M x 1 for imagenet1k\n",
    "    db_labels = np.load(ROOT_DIR + DATASET + \"_train_nesting1_sh0_ff2048-y.npy\")\n",
    "    # Query set: 50K x 1 for imagenet1k\n",
    "    query_labels = np.load(ROOT_DIR + DATASET + \"_val_nesting1_sh0_ff2048-y.npy\")\n",
    "    \n",
    "for dim in nesting_list:\n",
    "    start = time.time()\n",
    "    # Load database and query set for fixed feature models\n",
    "    if not NESTING:\n",
    "        db_labels = np.load(ROOT_DIR + DATASET + \"_train_nesting0_sh0_ff\" + str(dim) + \"-y.npy\")\n",
    "        query_labels = np.load(ROOT_DIR + DATASET + \"_val_nesting0_sh0_ff\" + str(dim) + \"-y.npy\")\n",
    "\n",
    "    # Load neighbors array and compute metrics\n",
    "    if EVAL_CONFIG == 'reranking':\n",
    "        print(\"\\nRet Dim: \", ret_dim)\n",
    "        print(\"Rerank dim: \", dim)\n",
    "        neighbors = pd.read_csv(ROOT_DIR + \"neighbors/reranked/\" + str(ret_dim) + \"dim-reranked\" + str(dim) + \"_2048shortlist_\"\n",
    "                                + DATASET + \"_\" + SEARCH_INDEX + \".csv\", header=None).to_numpy()\n",
    "    elif EVAL_CONFIG == 'vanilla':\n",
    "        print(\"\\nRet Dim: \", dim)\n",
    "        neighbors = pd.read_csv(ROOT_DIR + \"neighbors/\" + SEARCH_INDEX + \"_\" + str(dim) + \"dim_2048shortlist_\"\n",
    "                                + DATASET + \".csv\", header=None).to_numpy()\n",
    "    else:\n",
    "        neighbors = pd.read_csv(root_dir +\"neighbors/funnel_retrieval/\" + CASCADE_NN_FILE, header=None).to_numpy()\n",
    "\n",
    "    top1 = db_labels[neighbors[:, 0]]\n",
    "    print(\"Top1= \", np.sum(top1 == query_labels) / query_labels.shape[0])\n",
    "\n",
    "    shortlist = [10, 25, 50, 100] # compute metrics at different shortlist lengths\n",
    "    for k in shortlist:\n",
    "        mAP, precision, recall, topk = compute_mAP_recall_at_k(query_labels, db_labels, neighbors, k)\n",
    "        print(\"mAP@%d = %f\"%(k, mAP))\n",
    "        print(\"precision@%d = %f\"%(k, precision))\n",
    "        print(\"recall@%d = %f\"%(k, recall))\n",
    "        print(\"top%d = %f\"%(k, topk))\n",
    "\n",
    "    end = time.time()\n",
    "    print(\"Eval time for %d= %f\" %(dim, (end - start)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
