{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "aa3cf273",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fbeb4d",
   "metadata": {},
   "source": [
    "## Configuration Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6b093168",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = 'mrl/' # ['mrl/', 'mrl_e/', 'ff/']\n",
    "NESTING = CONFIG in ['mrl/', 'mrl_e/']\n",
    "ROOT_DIR = \"retrieval_array_path/\"\n",
    "DATASET = '1K' # ['1K', '4K', 'V2']\n",
    "SEARCH_INDEX = 'exactl2' # ['exactl2', 'hnsw_8', 'hnsw_32']\n",
    "EVAL_CONFIG = 'reranking' # ['vanilla', 'reranking', 'funnel']\n",
    "\n",
    "'''\n",
    "nesting_list is used in two ways depending on the config:\n",
    "1. vanilla: nesting_list = scales at which we retrieve representations for all images\n",
    "2. reranking: nesting_list = scales at which we rerank representations for all images\n",
    "3. funnel: unused\n",
    "'''\n",
    "if EVAL_CONFIG in ['vanilla', 'reranking']:\n",
    "    nesting_list = [8, 16, 32, 64, 128, 256, 512, 1024, 2048]\n",
    "elif EVAL_CONFIG == 'funnel':\n",
    "    # funnel retrieval\n",
    "    retrieval_dim = nesting_list = [8]  # for funnel, we evaluate a single config at a time\n",
    "    # rerank_dim: scale at which neighbors will be re-ordered based on L2 distance\n",
    "    rerank_dim = [16, 32, 64, 128, 2048]\n",
    "    # shortlist length which as 1-1 correspondence with rerank_dim\n",
    "    funnel_shortlist = [800,400,200,50,10]\n",
    "    CASCADE_NN_FILE = str(retrieval_dim[0])+\"dim-cascade\"+str(rerank_dim)+\"_\"+\"shortlist\"+ \\\n",
    "        str(funnel_shortlist)+\"_\"+DATASET+\"_\"+SEARCH_INDEX+\".csv\"\n",
    "else:\n",
    "    raise Exception(\"Unsupported Evaluation Config.\")\n",
    "\n",
    "'''\n",
    "ret_dim is used in two ways depending on the config:\n",
    "1. vanilla: unused\n",
    "2. reranking: retrieve representations of size ret_dim and rerank with nesting_list\n",
    "3. funnel: unused\n",
    "'''\n",
    "ret_dim = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9c9351db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mAP_recall_at_k(val_classes, db_classes, neighbors, k):\n",
    "    \"\"\"\n",
    "    Computes the MAP@k (default value of k=R) on neighbors with val set by seeing if nearest neighbor\n",
    "    is in the same class as the class of the val code. Let m be size of val set, and n in train.\n",
    "\n",
    "      val:          (m x d) All the truncated vector representations of images in val set\n",
    "      val_classes:  (m x 1) class index values for each vector in the val set\n",
    "      db_classes:   (n x 1) class index values for each vector in the train set\n",
    "      neighbors:    (k x m) indices in train set of top k neighbors for each vector in val set\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    ImageNet-1K:\n",
    "    shape of val is: (50000, dim)\n",
    "    shape of val_classes is: (50000, 1)\n",
    "    shape of db_classes is: (1281167, 1)\n",
    "    shape of neighbors is: (50000, 100))\n",
    "    \"\"\"\n",
    "\n",
    "    APs = list()\n",
    "    precision, recall, topk = [], [], []\n",
    "    for i in range(val_classes.shape[0]): # Compute precision for each vector's list of k-nn\n",
    "        target = val_classes[i]\n",
    "        indices = neighbors[i, :][:k]    # k neighbor list for ith val vector\n",
    "        labels = db_classes[indices]\n",
    "        matches = (labels == target)\n",
    "    \n",
    "        # topk\n",
    "        hits = np.sum(matches)\n",
    "        if hits>0:\n",
    "            topk.append(1)\n",
    "        else:\n",
    "            topk.append(0)\n",
    "            \n",
    "        # true positive counts\n",
    "        tps = np.cumsum(matches)\n",
    "\n",
    "        # recall\n",
    "        recall.append(np.sum(matches)/1300)\n",
    "        precision.append(np.sum(matches)/k)\n",
    "\n",
    "        # precision values\n",
    "        precs = tps.astype(float) / np.arange(1, k + 1, 1)\n",
    "        APs.append(np.sum(precs[matches.squeeze()]) / k)\n",
    "\n",
    "    return np.mean(APs), np.mean(precision), np.mean(recall), np.mean(topk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74005467",
   "metadata": {},
   "source": [
    "## Load database, query, and neighbor arrays and compute metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1245f078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating at k = [10, 25, 50, 100]\n",
      "\n",
      "Ret Dim:  8\n",
      "Rerank dim:  16\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'os' has no attribute 'exists'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [73]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported Evaluation Config.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexists\u001b[49m(neighbors):\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     40\u001b[0m top1 \u001b[38;5;241m=\u001b[39m db_labels[neighbors[:, \u001b[38;5;241m0\u001b[39m]]\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'os' has no attribute 'exists'"
     ]
    }
   ],
   "source": [
    "shortlist = [10, 25, 50, 100] # compute metrics at different shortlist lengths\n",
    "print(\"Evaluating at k =\", shortlist)\n",
    "\n",
    "# Load database and query set for nested models\n",
    "if NESTING:\n",
    "    # Database: 1.2M x 1 for imagenet1k\n",
    "    db_labels = np.load(ROOT_DIR + DATASET + \"_train_mrl1_e0_ff2048-y.npy\")\n",
    "    # Query set: 50K x 1 for imagenet1k\n",
    "    query_labels = np.load(ROOT_DIR + DATASET + \"_val_mrl1_e0_ff2048-y.npy\")\n",
    "    \n",
    "for dim in nesting_list:\n",
    "    start = time.time()\n",
    "    # Load database and query set for fixed feature models\n",
    "    if not NESTING:\n",
    "        db_labels = np.load(ROOT_DIR + DATASET + \"_train_mrl0_e0_ff\" + str(dim) + \"-y.npy\")\n",
    "        query_labels = np.load(ROOT_DIR + DATASET + \"_val_mrl0_e0_ff\" + str(dim) + \"-y.npy\")\n",
    "\n",
    "    # Load neighbors array and compute metrics\n",
    "    if EVAL_CONFIG == 'reranking':\n",
    "        print(\"\\nRet Dim: \", ret_dim)\n",
    "        print(\"Rerank dim: \", dim)\n",
    "        neighbors = pd.read_csv(ROOT_DIR + \"neighbors/reranked/\" + CONFIG + str(ret_dim) + \"dim-reranked\" \\\n",
    "                    + str(dim) + \"_200shortlist_\" + DATASET + \"_\" + SEARCH_INDEX + \".csv\", header=None).to_numpy()\n",
    "    elif EVAL_CONFIG == 'vanilla':\n",
    "        print(\"\\nRet Dim: \", dim)\n",
    "        neighbors = pd.read_csv(ROOT_DIR + \"neighbors/\" + CONFIG + SEARCH_INDEX + \"_\" + str(dim) \\\n",
    "                    + \"dim_2048shortlist_\" + DATASET + \".csv\", header=None).to_numpy()\n",
    "    elif EVAL_CONFIG == 'funnel':\n",
    "        neighbors = pd.read_csv(ROOT_DIR +\"neighbors/funnel_retrieval/\" + CONFIG \\\n",
    "                    + CASCADE_NN_FILE, header=None).to_numpy()\n",
    "        # remove shortlist elements longer than final funnel dimension\n",
    "        shortlist = [i for i in shortlist if i <= funnel_shortlist[-1]] \n",
    "        print(\"Updated funnel shortlist k =\", shortlist)\n",
    "    else:\n",
    "        raise Exception(\"Unsupported Evaluation Config.\")\n",
    "        \n",
    "    if not os.exists(neighbors):\n",
    "        continue\n",
    "        \n",
    "    top1 = db_labels[neighbors[:, 0]]\n",
    "    print(\"Top1= \", np.sum(top1 == query_labels) / query_labels.shape[0])\n",
    "    for k in shortlist:\n",
    "        mAP, precision, recall, topk = compute_mAP_recall_at_k(query_labels, db_labels, neighbors, k)\n",
    "        print(\"mAP@%d = %f\"%(k, mAP))\n",
    "        print(\"precision@%d = %f\"%(k, precision))\n",
    "        print(\"recall@%d = %f\"%(k, recall))\n",
    "        print(\"top%d = %f\"%(k, topk))\n",
    "    end = time.time()\n",
    "    print(\"Eval time for %d = %0.3f sec\\n\" %(dim, (end - start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e189fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
