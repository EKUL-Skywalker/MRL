{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72ee88c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47f81ed",
   "metadata": {},
   "source": [
    "## Configuration Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "763bdc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"ff/\" # mrl, mrl_e, ff\n",
    "root = \"path_to_r50_inference_arrays/\"\n",
    "use_funnel = True\n",
    "index_type = 'exactl2' # exactl2, hnsw8, hnsw32\n",
    "dataset = 'imagenet1k' # imagenet1k, imagenetv2, imagenet4m\n",
    "\n",
    "if not use_funnel:\n",
    "    nn_dir = root+\"neighbors/reranked/\"\n",
    "    rerank_dim = [2048]\n",
    "    shortlist = [200]\n",
    "else:\n",
    "    nn_dir = root+\"neighbors/funnel_retrieval/\"\n",
    "    # rerank_dim: scale at which neighbors will be re-ordered based on L2 distance\n",
    "    rerank_dim = [16, 32, 64, 128, 2048] # rerank cascade\n",
    "    # shortlist_set: set of shortlist cascades\n",
    "    shortlist_set = [[800,400,200,50,10], [400,200,50,25,10], [200,100,50,25,10]] \n",
    "\n",
    "max_rerank_dim = 2048 # maximum dimensionality at which reranking may occur, usually = 2048\n",
    "retrieval_dim = 8 # scale at which to retrieve 2048-NN for all samples in query set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73452fe1",
   "metadata": {},
   "source": [
    "## Load Database and Query vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11554e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load database vectors (10000 x 2048), time= 0.047169\n",
      "Load query vectors (10000 x 2048), time= 0.075541\n",
      "Normalization time= 0.145540\n"
     ]
    }
   ],
   "source": [
    "if model == 'mrl':\n",
    "    config = 'mrl1_e0_ff2048'\n",
    "elif model == 'mrl_e':\n",
    "    config = 'mrl0_e1_ff2048'\n",
    "\n",
    "db_csv = dataset + '_train_' + config + '-X.npy' # naming format as in R50_inference.py\n",
    "query_csv = dataset + '_val_' + config + '-X.npy'\n",
    "\n",
    "start = time.time()\n",
    "db_rerank = np.load(rootroot_dir+db_csv)[:, :max_rerank_dim]\n",
    "end = time.time() - start\n",
    "print(\"Load database vectors (%d x %d), time= %f\" % (db_rerank.shape[0], db_rerank.shape[1], end))\n",
    "\n",
    "start = time.time()\n",
    "queries = np.load(root+query_csv)[:, :max_rerank_dim]\n",
    "end = time.time() - start\n",
    "print(\"Load query vectors (%d x %d), time= %f\" % (queries.shape[0], queries.shape[1], end))\n",
    "\n",
    "start = time.time()\n",
    "queries = normalize(queries, axis=1)\n",
    "db_rerank = normalize(db_rerank, axis=1)\n",
    "end = time.time() - start\n",
    "print(\"Normalization time= %f\" % (end))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460d7628",
   "metadata": {},
   "source": [
    "## Load k-NN array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "983419a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded exactl2_8dim-2048-NN_imagenetv2.csv : (10000 x 2048), time= 1.090317\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "NN_file = root+\"neighbors/\"+index_type+\"_\"+ str(retrieval_dim)+\"dim-2048-NN_\"+dataset+\".csv\"\n",
    "neighbors = pd.read_csv(NN_file, header=None).to_numpy()\n",
    "\n",
    "end = time.time() - start\n",
    "print(\"Loaded %s : (%d x %d), time= %f\" % (NN_file.split(\"/\")[-1], neighbors.shape[0], neighbors.shape[1], end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a124302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DB for reranking:  (10000, 2048)\n",
      "Queries for reranking:  (10000, 2048)\n",
      "k-NN array:  (10000, 2048)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDB for reranking: \", db_rerank.shape)\n",
    "print(\"Queries for reranking: \", queries.shape)\n",
    "print(\"k-NN array: \", neighbors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a628d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank(use_funnel, rerank_dim, shortlist, neighbors):\n",
    "    \"\"\" Return shortlist of 2048-NN reranked with D_s and retrieved with D_r \n",
    "    \n",
    "    Keyword arguments:\n",
    "    use_funnel -- boolean flag to rerank in a cascaded fashion via funnel retrieval\n",
    "    rerank_dim -- dimensionality at which to rerank shortlist of k-NN\n",
    "    shortlist -- length of k-NN retrieved\n",
    "    neighbors -- array of k-NN indexed on db_csv\n",
    "    \"\"\"\n",
    "    # ensure these match for funnel\n",
    "    if use_funnel:\n",
    "        assert len(rerank_dim) == len(shortlist)\n",
    "\n",
    "    for i in range(len(rerank_dim)):\n",
    "        db_rerank_new = db_rerank[:, :rerank_dim[i]]\n",
    "        neighbors_new = neighbors[:, :shortlist[i]]\n",
    "\n",
    "        # iterate over every query and re-order 2048-NN based on rerank_dim representation distances\n",
    "        for j in range(len(neighbors)):\n",
    "            query_vector = queries[j][:rerank_dim[i]]\n",
    "            #print(\"Query vector: \", query_vector.shape)\n",
    "            nn_indices = neighbors_new[j][:shortlist[i]]\n",
    "\n",
    "            #NN_vectors_original = normalize(db_retrieval[nn_indices].squeeze(), axis = 1)\n",
    "            NN_vectors_higher_dim = normalize(db_rerank_new[nn_indices].squeeze(), axis=1)\n",
    "            #print(\"NN vector original and higher dim: \", NN_vectors_original.shape, NN_vectors_higher_dim.shape)\n",
    "\n",
    "            #L2_distances_orig = np.linalg.norm(NN_vectors_original - query_vector[:retrieval_dim], axis=1)\n",
    "            #print(\"Sorting at retrieval dim: \", np.argsort(L2_distances_orig)[:10]) #sanity test this should be 0, 1, 2 ...\n",
    "            L2_distances_reranked = np.linalg.norm(NN_vectors_higher_dim - query_vector[:rerank_dim[i]], axis=1)\n",
    "            #print(\"Sorting at rerank dim: \", np.argsort(L2_distances_reranked)[:10]) #reorder indices based on higher dim representations\n",
    "\n",
    "            reranked_neighbor_indices = np.argsort(L2_distances_reranked)\n",
    "            reranked_neighbors = neighbors_new[j, reranked_neighbor_indices]\n",
    "            neighbors_new[j] = reranked_neighbors\n",
    "        #print(\"DB rerank: \", db_rerank_new.shape)\n",
    "        #print(\"Neighbors: \", neighbors_new.shape)\n",
    "        neighbors = neighbors_new\n",
    "    return neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed43a3a",
   "metadata": {},
   "source": [
    "## Retrieve k-NN array with D_r and rerank with D_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "691937a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retrieve @8 + rerank@16, time = 0.775230\n",
      "(10000, 200)\n",
      "Saving config:  8dim-reranked16_200shortlist_imagenetv2_exactl2.csv\n",
      "\n",
      "Retrieve @8 + rerank@32, time = 0.814424\n",
      "(10000, 200)\n",
      "Saving config:  8dim-reranked32_200shortlist_imagenetv2_exactl2.csv\n",
      "\n",
      "Retrieve @8 + rerank@64, time = 0.882801\n",
      "(10000, 200)\n",
      "Saving config:  8dim-reranked64_200shortlist_imagenetv2_exactl2.csv\n",
      "\n",
      "Retrieve @8 + rerank@128, time = 1.074831\n",
      "(10000, 200)\n",
      "Saving config:  8dim-reranked128_200shortlist_imagenetv2_exactl2.csv\n",
      "\n",
      "Retrieve @8 + rerank@2048, time = 6.858704\n",
      "(10000, 200)\n",
      "Saving config:  8dim-reranked2048_200shortlist_imagenetv2_exactl2.csv\n"
     ]
    }
   ],
   "source": [
    "for dim in rerank_dim:\n",
    "    start = time.time()\n",
    "    neighbors_reranked = rerank(use_funnel, [dim], shortlist, neighbors)\n",
    "    end = time.time() - start\n",
    "    print(\"\\nD_r = %d , D_s = %d, time = %f\" % (retrieval_dim, dim, end))\n",
    "\n",
    "    neighbors_df = pd.DataFrame(neighbors_reranked)\n",
    "    print(neighbors_df.shape)\n",
    "\n",
    "    if not os.path.isdir(nn_dir):\n",
    "        os.makedirs(nn_dir)\n",
    "\n",
    "    filename = str(retrieval_dim)+\"dim-reranked\"+str(dim)+\"_\"+str(shortlist[0])+\"shortlist_\"+dataset+\"_\"+index_type+\".csv\"\n",
    "\n",
    "    print(\"Saving config: \", filename)\n",
    "    pd.DataFrame(neighbors_df).to_csv(nn_dir+filename, header=None, index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd9efcf",
   "metadata": {},
   "source": [
    "## Funnel Retrieval (increase dims and reduce shortlist length in sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2c779d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retrieve @8 + funnel retrieval @[16, 32, 64, 128, 2048] with shortlist [800, 400, 200, 50, 10], time = 5.074842\n",
      "(10000, 10)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "bad operand type for unary +: 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(neighbors_df\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     12\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(retrieval_dim)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdim-cascade\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(rerank_dim)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(shortlist)\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshortlist_\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241m+\u001b[39mdataset\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mindex_type\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaving config: \u001b[39m\u001b[38;5;124m\"\u001b[39m, filename)\n\u001b[1;32m     16\u001b[0m pd\u001b[38;5;241m.\u001b[39mDataFrame(neighbors_df)\u001b[38;5;241m.\u001b[39mto_csv(nn_dir\u001b[38;5;241m+\u001b[39mfilename, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: bad operand type for unary +: 'str'"
     ]
    }
   ],
   "source": [
    "if use_funnel:\n",
    "    for shortlist in shortlist_set:\n",
    "        start = time.time()\n",
    "        NN_cascade = rerank(1, rerank_dim, shortlist, neighbors)\n",
    "        end = time.time() - start\n",
    "        print(\"\\nRetrieve @%d + funnel retrieval @%s with shortlist %s, time = %f\" \n",
    "              % (retrieval_dim, rerank_dim, shortlist, end))\n",
    "\n",
    "        neighbors_df = pd.DataFrame(NN_cascade)\n",
    "        print(neighbors_df.shape)\n",
    "\n",
    "        filename = str(retrieval_dim)+\"dim-cascade\"+str(rerank_dim)+\"_\"+\"shortlist\"+str(shortlist)+\"_\"+dataset+\"_\"+index_type+\".csv\"\n",
    "\n",
    "        print(\"Saving config: \", filename)\n",
    "        pd.DataFrame(neighbors_df).to_csv(nn_dir+filename, header=None, index=None)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
