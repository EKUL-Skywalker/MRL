{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "72ee88c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "763bdc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = 'multihead/'\n",
    "root_dir = \"/mnt/disks/retrieval/corrected_fwd_pass/\"+config\n",
    "index = 'exactl2'\n",
    "dataset = 'imagenet1k'\n",
    "use_cascade = 0\n",
    "\n",
    "retrieval_dim = 16 # scale at which to retrieve 100-NN for all samples in query set\n",
    "max_retrieval_dim = 2048\n",
    "max_rerank_dim = 2048\n",
    "rerank_dim = [2048] # scale at which neighbors will be re-ordered based on L2 distance\n",
    "#rerank_dim = [16,32,64,128,2048]\n",
    "#shortlist = [200,100,50,25,10] # corresponding shortlist length for reranking\n",
    "shortlist = [100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "11554e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load database vectors (1281167 x 2048), time= 60.301246\n",
      "Load query vectors (50000 x 2048), time= 0.987897\n",
      "Normalization time= 188.171419\n"
     ]
    }
   ],
   "source": [
    "# Load knn array, database vectors, and query vectors\n",
    "db_csv = dataset+'_train_nesting1_sh0_ff2048-X.npy'\n",
    "query_csv = dataset+'_val_nesting1_sh0_ff2048-X.npy'\n",
    "\n",
    "start = time.time()\n",
    "db_rerank = np.load(root_dir+db_csv)[:, :max_rerank_dim]\n",
    "end = time.time() - start\n",
    "print(\"Load database vectors (%d x %d), time= %f\" % (db_rerank.shape[0], db_rerank.shape[1], end))\n",
    "\n",
    "start = time.time()\n",
    "queries = np.load(root_dir+query_csv)[:, :max_rerank_dim]\n",
    "end = time.time() - start\n",
    "print(\"Load query vectors (%d x %d), time= %f\" % (queries.shape[0], queries.shape[1], end))\n",
    "\n",
    "start = time.time()\n",
    "queries = normalize(queries, axis=1)\n",
    "db_rerank = normalize(db_rerank, axis=1)\n",
    "end = time.time() - start\n",
    "print(\"Normalization time= %f\" % (end))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460d7628",
   "metadata": {},
   "source": [
    "## Modify below to avoid expensive file loads for 4M dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "983419a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded exactl2_16dim-2048-NN_imagenet1k.csv : (50000 x 2048), time= 12.993581\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "NN_file = root_dir+\"neighbors/\"+index+\"_\"+ str(retrieval_dim)+\"dim-2048-NN_\"+dataset+\".csv\"\n",
    "neighbors = pd.read_csv(NN_file, header=None).to_numpy()\n",
    "\n",
    "end = time.time() - start\n",
    "print(\"Loaded %s : (%d x %d), time= %f\" % (NN_file.split(\"/\")[-1], neighbors.shape[0], neighbors.shape[1], end))\n",
    "\n",
    "# db_retrieval = db_rerank[:, :max_retrieval_dim]\n",
    "# db_retrieval = normalize(db_retrieval, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "1a124302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DB for reranking:  (1281167, 2048)\n",
      "Queries for reranking:  (50000, 2048)\n",
      "k-NN array:  (50000, 2048)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDB for reranking: \", db_rerank.shape)\n",
    "print(\"Queries for reranking: \", queries.shape)\n",
    "print(\"k-NN array: \", neighbors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f88d0a",
   "metadata": {},
   "source": [
    "# Naive Routing/Cascading Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "7a628d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_rerank(use_cascade, rerank_dim, shortlist, neighbors):\n",
    "    \n",
    "    # ensure these match for naive routing strategy\n",
    "    if use_cascade:\n",
    "        assert len(rerank_dim) == len(shortlist)\n",
    "\n",
    "    for i in range(len(rerank_dim)):\n",
    "        db_rerank_new = db_rerank[:, :rerank_dim[i]]\n",
    "        neighbors_new = neighbors[:, :shortlist[i]]\n",
    "\n",
    "        # iterate over every query and re-order 100-NN based on 2048 dim distances\n",
    "        for j in range(len(neighbors)):\n",
    "        #for j in range(2):\n",
    "            query_vector = queries[j][:rerank_dim[i]]\n",
    "            #print(\"Query vector: \", query_vector.shape)\n",
    "            nn_indices = neighbors_new[j][:shortlist[i]]\n",
    "\n",
    "            #NN_vectors_original = normalize(db_retrieval[nn_indices].squeeze(), axis = 1)\n",
    "            NN_vectors_higher_dim = normalize(db_rerank_new[nn_indices].squeeze(), axis=1)\n",
    "            #print(\"NN vector original and higher dim: \", NN_vectors_original.shape, NN_vectors_higher_dim.shape)\n",
    "\n",
    "            #L2_distances_orig = np.linalg.norm(NN_vectors_original - query_vector[:retrieval_dim], axis=1)\n",
    "            #print(\"Sorting at retrieval dim: \", np.argsort(L2_distances_orig)[:10]) #sanity test this should be 0, 1, 2 ...\n",
    "            L2_distances_reranked = np.linalg.norm(NN_vectors_higher_dim - query_vector[:rerank_dim[i]], axis=1)\n",
    "            #print(\"Sorting at rerank dim: \", np.argsort(L2_distances_reranked)[:10]) #reorder indices based on higher dim representations\n",
    "\n",
    "            reranked_neighbor_indices = np.argsort(L2_distances_reranked)\n",
    "            reranked_neighbors = neighbors_new[j, reranked_neighbor_indices]\n",
    "            neighbors_new[j] = reranked_neighbors\n",
    "        #print(\"DB rerank: \", db_rerank_new.shape)\n",
    "        #print(\"Neighbors: \", neighbors_new.shape)\n",
    "        neighbors = neighbors_new\n",
    "    return neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed43a3a",
   "metadata": {},
   "source": [
    "## Rerank over rerank_dim list for fixed shortlist length k. Retrieval dim is also fixed and loaded from NN.csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "a2731bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "shortlist_list = [[200]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "691937a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retrieve @16 + rerank@2048, time = 83.435824\n",
      "(50000, 200)\n",
      "Saving config:  16dim-reranked2048_200shortlist_imagenet1k_exactl2.csv\n"
     ]
    }
   ],
   "source": [
    "for shortlist in shortlist_list:\n",
    "    for dim in rerank_dim:\n",
    "        start = time.time()\n",
    "        neighbors_reranked = naive_rerank(use_cascade, [dim], shortlist, neighbors)\n",
    "        end = time.time() - start\n",
    "        print(\"\\nRetrieve @%d + rerank@%d, time = %f\" % (retrieval_dim, dim, end))\n",
    "\n",
    "        neighbors_df = pd.DataFrame(neighbors_reranked)\n",
    "        print(neighbors_df.shape)\n",
    "\n",
    "        if not use_cascade:\n",
    "            nn_dir = root_dir+\"neighbors/reranked/\"\n",
    "        else:\n",
    "            nn_dir = root_dir+\"neighbors/cascade_naive_policy/\"\n",
    "\n",
    "        if not os.path.isdir(nn_dir):\n",
    "            os.makedirs(nn_dir)\n",
    "\n",
    "        filename = str(retrieval_dim)+\"dim-reranked\"+str(dim)+\"_\"+str(shortlist[0])+\"shortlist_\"+dataset+\"_\"+index+\".csv\"\n",
    "\n",
    "        print(\"Saving config: \", filename)\n",
    "        #pd.DataFrame(neighbors_df).to_csv(nn_dir+filename, header=None, index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd9efcf",
   "metadata": {},
   "source": [
    "## Funnel Retrieval (increase dims and reduce shortlist length in sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "564e87f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "shortlist_set = [[800,400,200,50,10], [400,200,50,25,10], [200,100,50,25,10]]\n",
    "# corresponding shortlist length for reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "2c779d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retrieve @8 + cascade naive policy @[16, 32, 64, 128, 2048] with shortlist [800, 400, 200, 50, 10], time = 245.806595\n",
      "(210100, 10)\n",
      "Saving config:  8dim-cascade[16, 32, 64, 128, 2048]_[800, 400, 200, 50, 10]shortlist_imagenet4m_exactl2.csv\n",
      "\n",
      "Retrieve @8 + cascade naive policy @[16, 32, 64, 128, 2048] with shortlist [400, 200, 50, 25, 10], time = 176.763507\n",
      "(210100, 10)\n",
      "Saving config:  8dim-cascade[16, 32, 64, 128, 2048]_[400, 200, 50, 25, 10]shortlist_imagenet4m_exactl2.csv\n",
      "\n",
      "Retrieve @8 + cascade naive policy @[16, 32, 64, 128, 2048] with shortlist [200, 100, 50, 25, 10], time = 152.884837\n",
      "(210100, 10)\n",
      "Saving config:  8dim-cascade[16, 32, 64, 128, 2048]_[200, 100, 50, 25, 10]shortlist_imagenet4m_exactl2.csv\n"
     ]
    }
   ],
   "source": [
    "for shortlist in shortlist_set:\n",
    "    start = time.time()\n",
    "    NN_cascade = naive_rerank(1, rerank_dim, shortlist, neighbors)\n",
    "    end = time.time() - start\n",
    "    print(\"\\nRetrieve @%d + cascade naive policy @%s with shortlist %s, time = %f\" \n",
    "          % (retrieval_dim, rerank_dim, shortlist, end))\n",
    "\n",
    "    neighbors_df = pd.DataFrame(NN_cascade)\n",
    "    print(neighbors_df.shape)\n",
    "\n",
    "    nn_dir = root_dir+\"neighbors/cascade_naive_policy/\"\n",
    "    filename = str(retrieval_dim)+\"dim-cascade\"+str(rerank_dim)+\"_\"+str(shortlist)+\"shortlist_\"+dataset+\"_\"+index+\".csv\"\n",
    "\n",
    "    print(\"Saving config: \", filename)\n",
    "    pd.DataFrame(neighbors_df).to_csv(nn_dir+filename, header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "5578fc51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving config:  64dim-cascade[128, 256, 512, 1024, 2048]_[200, 100, 50, 25, 10]shortlist_imagenet4m_exactl2.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"Saving config: \", filename)\n",
    "pd.DataFrame(neighbors_df).to_csv(nn_dir+filename, header=None, index=None)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}